# Documentaci√≥n: Gesti√≥n de Permisos HDFS y Creaci√≥n de Directorios

## üìã Problema Com√∫n: Permission Denied en HDFS

### Error T√≠pico
```
Permission denied: user=dr.who, access=WRITE, inode="/":root:supergroup:drwxr-xr-x
```

### Causa
- El directorio ra√≠z `/` de HDFS pertenece a `root:supergroup`
- Tiene permisos `755` (solo el propietario puede escribir)
- Los usuarios no privilegiados no pueden escribir en la ra√≠z

## üõ†Ô∏è Soluci√≥n Recomendada para Producci√≥n

### 1. Verificar Estado Actual
```bash
# Acceder al contenedor/servidor Had

# Verificar permisos del directorio ra√≠z
hdfs dfs -ls /
hdfs dfs -getfacl /

# Verificar usuario actual
whoami
```

### 2. Crear Directorio de Usuario (Recomendado)
```bash
# Crear directorio espec√≠fico para el usuario
hdfs dfs -mkdir -p /user/[NOMBRE_USUARIO]

# Asignar propiedad al usuario
hdfs dfs -chown [NOMBRE_USUARIO]:supergroup /user/[NOMBRE_USUARIO]

# Establecer permisos apropiados
hdfs dfs -chmod 755 /user/[NOMBRE_USUARIO]
```

### 3. Crear Carpeta de Proyecto
```bash
# Crear carpeta espec√≠fica del proyecto
hdfs dfs -mkdir -p /user/[NOMBRE_USUARIO]/[NOMBRE_PROYECTO]

# Asignar propiedad
hdfs dfs -chown [NOMBRE_USUARIO]:supergroup /user/[NOMBRE_USUARIO]/[NOMBRE_PROYECTO]

# Establecer permisos
hdfs dfs -chmod 755 /user/[NOMBRE_USUARIO]/[NOMBRE_PROYECTO]
```

## üìù Ejemplo Pr√°ctico

### Para usuario 'dr.who' y proyecto 'LakeHousePruebas'
```bash
# Paso 1: Crear directorio de usuario
hdfs dfs -mkdir -p /user/dr.who
hdfs dfs -chown dr.who:supergroup /user/dr.who
hdfs dfs -chmod 755 /user/dr.who

# Paso 2: Crear carpeta del proyecto
hdfs dfs -mkdir -p /user/dr.who/LakeHousePruebas
hdfs dfs -chown dr.who:supergroup /user/dr.who/LakeHousePruebas
hdfs dfs -chmod 755 /user/dr.who/LakeHousePruebas

# Paso 3: Verificar estructura
hdfs dfs -ls -R /user
hdfs dfs -getfacl /user/dr.who/LakeHousePruebas
```

## üîÑ Comandos de Gesti√≥n de Permisos

### Cambiar Propietario Recursivamente
```bash
# Cambiar propietario de un directorio y todos sus subdirectorios
hdfs dfs -chown -R [USUARIO]:[GRUPO] [RUTA]

# Ejemplo: Cambiar todas las carpetas de LakeHouse a dr.who
hdfs dfs -chown -R dr.who:supergroup /user/dr.who/LakeHouse/
```

**Descripci√≥n**: El comando `chown -R` cambia recursivamente el propietario de un directorio y todos sus contenidos. √ötil cuando se crean carpetas desde notebooks que ejecutan como root y necesitan pertenecer al usuario espec√≠fico.

### Cambiar Permisos Recursivamente
```bash
# Cambiar permisos de un directorio y todos sus subdirectorios
hdfs dfs -chmod -R [PERMISOS] [RUTA]

# Ejemplo: Dar permisos de lectura/escritura recursivamente
hdfs dfs -chmod -R 755 /user/dr.who/LakeHouse/
```

**Descripci√≥n**: El comando `chmod -R` cambia recursivamente los permisos de acceso. Los permisos 755 permiten lectura/escritura/ejecuci√≥n al propietario y lectura/ejecuci√≥n al grupo y otros.

### Verificar Permisos Espec√≠ficos
```bash
# Listar permisos de un directorio espec√≠fico
hdfs dfs -ls -d [RUTA]

# Ejemplo: Ver permisos del directorio staging
hdfs dfs -ls -d /user/dr.who/LakeHouse/staging
```

**Descripci√≥n**: El comando `ls -d` muestra informaci√≥n solo del directorio especificado (no su contenido), √∫til para verificar propietario y permisos de una carpeta espec√≠fica.

## üåê Configuraci√≥n WebHDFS y CORS

### Habilitar WebHDFS
Para permitir cargas de archivos desde la interfaz web, agregar en `hdfs-site.xml`:
```xml
<property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
</property>
<property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:9864</value>
</property>
<property>
    <name>dfs.datanode.hostname</name>
    <value>localhost</value>
</property>
```

### Configurar CORS
Para resolver problemas de carga desde navegador, agregar en `core-site.xml`:
```xml
<property>
    <name>hadoop.http.cross-origin.enabled</name>
    <value>true</value>
</property>
<property>
    <name>hadoop.http.cross-origin.allowed-origins</name>
    <value>*</value>
</property>
<property>
    <name>hadoop.http.cross-origin.allowed-methods</name>
    <value>GET,POST,HEAD,PUT,DELETE</value>
</property>
<property>
    <name>hadoop.http.cross-origin.allowed-headers</name>
    <value>X-Requested-With,Content-Type,Accept,Origin</value>
</property>
```

**Nota**: Despu√©s de modificar estas configuraciones, es necesario reiniciar los servicios de Hadoop.

## üîß Comandos de Verificaci√≥n

### Verificar Servicios HDFS
```bash
# Ver procesos Java ejecut√°ndose
jps

# Verificar estado de HDFS
hdfs dfsadmin -report

# Verificar conectividad
hdfs dfs -ls /

# Probar WebHDFS
curl -i 'http://localhost:9870/webhdfs/v1/user/dr.who/LakeHouse/staging?op=LISTSTATUS'
```

### Verificar Permisos
```bash
# Listar con permisos detallados
hdfs dfs -ls -la /user/[USUARIO]

# Ver ACLs completas
hdfs dfs -getfacl /user/[USUARIO]/[PROYECTO]

# Verificar espacio disponible
hdfs dfs -df -h
```

## üåê Acceso desde Interfaz Web

### HDFS Web UI (Puerto 9870)
1. Abrir navegador: `http://localhost:9870`
2. Ir a `Utilities` ‚Üí `Browse the file system`
3. Navegar a `/user/[USUARIO]/[PROYECTO]`
4. Usar bot√≥n "Upload Files" para subir archivos

### Puertos Importantes
- **HDFS NameNode UI**: 9870
- **YARN ResourceManager**: 8088
- **Spark Master UI**: 8080
- **Spark Application UI**: 4040
- **Jupyter Notebook**: 8888

## ‚ö†Ô∏è Alternativas (Solo para Desarrollo)

### Opci√≥n 1: Cambiar Permisos Globales
```bash
# ‚ö†Ô∏è SOLO PARA DESARROLLO - No recomendado en producci√≥n
hdfs dfs -chmod 777 /
```

### Opci√≥n 2: Usar Usuario Root
```bash
# Cambiar al usuario root
su - root
# O ejecutar comandos espec√≠ficos como root
sudo -u root hdfs dfs -mkdir /mi_directorio
```

## üîí Mejores Pr√°cticas de Seguridad

### 1. Estructura de Directorios
```
/
‚îú‚îÄ‚îÄ user/
‚îÇ   ‚îú‚îÄ‚îÄ usuario1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ proyecto1/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ proyecto2/
‚îÇ   ‚îî‚îÄ‚îÄ usuario2/
‚îÇ       ‚îî‚îÄ‚îÄ datos/
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îî‚îÄ‚îÄ common_data/
‚îî‚îÄ‚îÄ tmp/
    ‚îî‚îÄ‚îÄ staging/
```

### 2. Permisos Recomendados
- **Directorio ra√≠z (/)**: `755` (root:supergroup)
- **Directorio usuario (/user/username)**: `755` (username:supergroup)
- **Proyectos espec√≠ficos**: `755` (username:supergroup)
- **Datos compartidos**: `775` (root:shared_group)

### 3. Comandos de Gesti√≥n
```bash
# Crear usuario nuevo
hdfs dfs -mkdir -p /user/nuevo_usuario
hdfs dfs -chown nuevo_usuario:supergroup /user/nuevo_usuario
hdfs dfs -chmod 755 /user/nuevo_usuario

# Crear directorio compartido
hdfs dfs -mkdir -p /shared/common
hdfs dfs -chown root:shared_group /shared/common
hdfs dfs -chmod 775 /shared/common

# Limpiar directorio temporal
hdfs dfs -rm -r /tmp/*
```

## üö® Soluci√≥n de Problemas

### Problema: DataNode no responde
```bash
# Verificar logs
tail -f $HADOOP_HOME/logs/hadoop-*-datanode-*.log

# Reiniciar servicios
$HADOOP_HOME/sbin/stop-dfs.sh
$HADOOP_HOME/sbin/start-dfs.sh
```

### Problema: Espacio insuficiente
```bash
# Verificar espacio en disco
df -h

# Verificar espacio HDFS
hdfs dfs -df -h

# Limpiar archivos temporales
hdfs dfs -rm -r /tmp/*
```

### Problema: Usuario no existe
```bash
# Crear usuario en el sistema (si es necesario)
useradd -m nuevo_usuario

# Crear directorio HDFS
hdfs dfs -mkdir -p /user/nuevo_usuario
hdfs dfs -chown nuevo_usuario:supergroup /user/nuevo_usuario
```

## üìö Referencias

- [Documentaci√≥n oficial de Hadoop HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html)
- [Gu√≠a de permisos HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html)
- [Comandos HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)

---

**Nota**: Esta documentaci√≥n est√° basada en Hadoop 3.3.6 y puede requerir ajustes para otras versiones.