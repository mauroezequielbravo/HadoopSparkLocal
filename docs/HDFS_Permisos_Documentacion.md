# Documentaci√≥n: Gesti√≥n de Permisos HDFS y Creaci√≥n de Directorios

## üìã Problema Com√∫n: Permission Denied en HDFS

### Error T√≠pico
```
Permission denied: user=dr.who, access=WRITE, inode="/":root:supergroup:drwxr-xr-x
```

### Causa
- El directorio ra√≠z `/` de HDFS pertenece a `root:supergroup`
- Tiene permisos `755` (solo el propietario puede escribir)
- Los usuarios no privilegiados no pueden escribir en la ra√≠z

## üõ†Ô∏è Soluci√≥n Recomendada para Producci√≥n

### 1. Verificar Estado Actual
```bash
# Acceder al contenedor/servidor Hadoop
docker exec -it hadoop-spark-jupyter bash

# Verificar permisos del directorio ra√≠z
hdfs dfs -ls /
hdfs dfs -getfacl /

# Verificar usuario actual
whoami
```

### 2. Crear Directorio de Usuario (Recomendado)
```bash
# Crear directorio espec√≠fico para el usuario
hdfs dfs -mkdir -p /user/[NOMBRE_USUARIO]

# Asignar propiedad al usuario
hdfs dfs -chown [NOMBRE_USUARIO]:supergroup /user/[NOMBRE_USUARIO]

# Establecer permisos apropiados
hdfs dfs -chmod 755 /user/[NOMBRE_USUARIO]
```

### 3. Crear Carpeta de Proyecto
```bash
# Crear carpeta espec√≠fica del proyecto
hdfs dfs -mkdir -p /user/[NOMBRE_USUARIO]/[NOMBRE_PROYECTO]

# Asignar propiedad
hdfs dfs -chown [NOMBRE_USUARIO]:supergroup /user/[NOMBRE_USUARIO]/[NOMBRE_PROYECTO]

# Establecer permisos
hdfs dfs -chmod 755 /user/[NOMBRE_USUARIO]/[NOMBRE_PROYECTO]
```

## üìù Ejemplo Pr√°ctico

### Para usuario 'dr.who' y proyecto 'LakeHousePruebas'
```bash
# Paso 1: Crear directorio de usuario
hdfs dfs -mkdir -p /user/dr.who
hdfs dfs -chown dr.who:supergroup /user/dr.who
hdfs dfs -chmod 755 /user/dr.who

# Paso 2: Crear carpeta del proyecto
hdfs dfs -mkdir -p /user/dr.who/LakeHousePruebas
hdfs dfs -chown dr.who:supergroup /user/dr.who/LakeHousePruebas
hdfs dfs -chmod 755 /user/dr.who/LakeHousePruebas

# Paso 3: Verificar estructura
hdfs dfs -ls -R /user
hdfs dfs -getfacl /user/dr.who/LakeHousePruebas
```

## üîß Comandos de Verificaci√≥n

### Verificar Servicios HDFS
```bash
# Ver procesos Java ejecut√°ndose
jps

# Verificar estado de HDFS
hdfs dfsadmin -report

# Verificar conectividad
hdfs dfs -ls /
```

### Verificar Permisos
```bash
# Listar con permisos detallados
hdfs dfs -ls -la /user/[USUARIO]

# Ver ACLs completas
hdfs dfs -getfacl /user/[USUARIO]/[PROYECTO]

# Verificar espacio disponible
hdfs dfs -df -h
```

## üåê Acceso desde Interfaz Web

### HDFS Web UI (Puerto 9870)
1. Abrir navegador: `http://localhost:9870`
2. Ir a `Utilities` ‚Üí `Browse the file system`
3. Navegar a `/user/[USUARIO]/[PROYECTO]`
4. Usar bot√≥n "Upload Files" para subir archivos

### Puertos Importantes
- **HDFS NameNode UI**: 9870
- **YARN ResourceManager**: 8088
- **Spark Master UI**: 8080
- **Spark Application UI**: 4040
- **Jupyter Notebook**: 8888

## ‚ö†Ô∏è Alternativas (Solo para Desarrollo)

### Opci√≥n 1: Cambiar Permisos Globales
```bash
# ‚ö†Ô∏è SOLO PARA DESARROLLO - No recomendado en producci√≥n
hdfs dfs -chmod 777 /
```

### Opci√≥n 2: Usar Usuario Root
```bash
# Cambiar al usuario root
su - root
# O ejecutar comandos espec√≠ficos como root
sudo -u root hdfs dfs -mkdir /mi_directorio
```

## üîí Mejores Pr√°cticas de Seguridad

### 1. Estructura de Directorios
```
/
‚îú‚îÄ‚îÄ user/
‚îÇ   ‚îú‚îÄ‚îÄ usuario1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ proyecto1/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ proyecto2/
‚îÇ   ‚îî‚îÄ‚îÄ usuario2/
‚îÇ       ‚îî‚îÄ‚îÄ datos/
‚îú‚îÄ‚îÄ shared/
‚îÇ   ‚îî‚îÄ‚îÄ common_data/
‚îî‚îÄ‚îÄ tmp/
    ‚îî‚îÄ‚îÄ staging/
```

### 2. Permisos Recomendados
- **Directorio ra√≠z (/)**: `755` (root:supergroup)
- **Directorio usuario (/user/username)**: `755` (username:supergroup)
- **Proyectos espec√≠ficos**: `755` (username:supergroup)
- **Datos compartidos**: `775` (root:shared_group)

### 3. Comandos de Gesti√≥n
```bash
# Crear usuario nuevo
hdfs dfs -mkdir -p /user/nuevo_usuario
hdfs dfs -chown nuevo_usuario:supergroup /user/nuevo_usuario
hdfs dfs -chmod 755 /user/nuevo_usuario

# Crear directorio compartido
hdfs dfs -mkdir -p /shared/common
hdfs dfs -chown root:shared_group /shared/common
hdfs dfs -chmod 775 /shared/common

# Limpiar directorio temporal
hdfs dfs -rm -r /tmp/*
```

## üö® Soluci√≥n de Problemas

### Problema: DataNode no responde
```bash
# Verificar logs
tail -f $HADOOP_HOME/logs/hadoop-*-datanode-*.log

# Reiniciar servicios
$HADOOP_HOME/sbin/stop-dfs.sh
$HADOOP_HOME/sbin/start-dfs.sh
```

### Problema: Espacio insuficiente
```bash
# Verificar espacio en disco
df -h

# Verificar espacio HDFS
hdfs dfs -df -h

# Limpiar archivos temporales
hdfs dfs -rm -r /tmp/*
```

### Problema: Usuario no existe
```bash
# Crear usuario en el sistema (si es necesario)
useradd -m nuevo_usuario

# Crear directorio HDFS
hdfs dfs -mkdir -p /user/nuevo_usuario
hdfs dfs -chown nuevo_usuario:supergroup /user/nuevo_usuario
```

## üìö Referencias

- [Documentaci√≥n oficial de Hadoop HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html)
- [Gu√≠a de permisos HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html)
- [Comandos HDFS](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html)

---

**Nota**: Esta documentaci√≥n est√° basada en Hadoop 3.3.6 y puede requerir ajustes para otras versiones.