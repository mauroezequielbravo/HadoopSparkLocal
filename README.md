# Entorno Hadoop, Spark, Hive y Jupyter Notebook

Este proyecto proporciona un entorno Docker completo con Hadoop, Spark, Apache Hive y Jupyter Notebook integrados para procesamiento y anÃ¡lisis de Big Data.

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  PostgreSQL  â”‚â”€â”€â”‚   Hive       â”‚            â”‚
â”‚  â”‚ (Puerto 5433)â”‚  â”‚  Metastore   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                     â”‚
â”‚  â”‚   Hadoop     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   (HDFS)     â”‚         â”‚          â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚          â”‚          â”‚
â”‚                           â”‚          â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚          â”‚          â”‚
â”‚  â”‚ HiveServer2  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚          â”‚
â”‚                                      â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚          â”‚
â”‚  â”‚    Spark     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â”‚  + Jupyter   â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Servicios Disponibles

### Interfaz Web
- **Jupyter Notebook**: http://localhost:8888
- **HDFS NameNode UI**: http://localhost:9870
- **Spark Master UI**: http://localhost:8080
- **YARN ResourceManager UI**: http://localhost:8088
- **Spark Application UI**: http://localhost:4040
- **HiveServer2 Web UI**: http://localhost:10002

### Puertos de Servicios
- **HiveServer2 (JDBC)**: `localhost:10000`
- **Hive Metastore**: `localhost:9083`
- **PostgreSQL**: `localhost:5433` (puerto alternativo para evitar conflictos)

## ğŸš€ Inicio RÃ¡pido

### Iniciar el entorno completo

```powershell
# Construir e iniciar todos los servicios
docker-compose up --build -d

# Ver el estado de los contenedores
docker-compose ps
```

### Ver logs de los servicios

```powershell
# Ver todos los logs
docker-compose logs

# Ver logs en tiempo real
docker-compose logs -f

# Ver logs de servicios especÃ­ficos
docker-compose logs -f hadoop
docker-compose logs -f spark
docker-compose logs -f hive-server
docker-compose logs -f hive-metastore
docker-compose logs -f postgres
```

### Detener y reiniciar servicios

```powershell
# Detener todos los contenedores
docker-compose down

# Reiniciar servicios especÃ­ficos
docker-compose restart hive-server
docker-compose restart spark

# Detener y eliminar volÃºmenes (âš ï¸ elimina datos persistentes)
docker-compose down -v
```

## ğŸ Trabajar con Hive

### Conectarse a HiveServer2 con Beeline

```powershell
# Acceder al contenedor y ejecutar Beeline
docker exec -it hive-server beeline -u jdbc:hive2://localhost:10000
```

### Ejemplo rÃ¡pido de uso

```sql
-- Crear base de datos
CREATE DATABASE IF NOT EXISTS test_db;
USE test_db;

-- Crear tabla
CREATE TABLE IF NOT EXISTS usuarios (
    id INT,
    nombre STRING,
    edad INT
);

-- Insertar datos
INSERT INTO usuarios VALUES (1, 'Juan', 30), (2, 'MarÃ­a', 25);

-- Consultar
SELECT * FROM usuarios;
```

### Usar Hive desde Jupyter (PySpark)

```python
from pyspark.sql import SparkSession

# Crear sesiÃ³n con soporte Hive
spark = SparkSession.builder \
    .appName("Hive Example") \
    .config("hive.metastore.uris", "thrift://hive-metastore:9083") \
    .enableHiveSupport() \
    .getOrCreate()

# Consultar tabla de Hive
df = spark.sql("SELECT * FROM test_db.usuarios")
df.show()
```

**ğŸ“– DocumentaciÃ³n completa de Hive:** [docs/HIVE_Documentacion.md](docs/HIVE_Documentacion.md)

## ğŸ”§ GestiÃ³n Avanzada

### Acceder a los contenedores

```powershell
# Acceder al contenedor de Hadoop
docker exec -it hadoop-master bash

# Acceder al contenedor de Spark
docker exec -it spark-master bash

# Acceder al contenedor de Hive
docker exec -it hive-server bash

# Acceder a PostgreSQL
docker exec -it postgres-hive-metastore psql -U hive -d metastore
```

### Verificar estado de servicios

```powershell
# Ver procesos Java en Hadoop
docker exec hadoop-master jps

# Ver procesos Java en Spark
docker exec spark-master jps

# Verificar conectividad de Hive con el Metastore
docker exec hive-server nc -zv hive-metastore 9083

# Verificar estado de PostgreSQL
docker exec postgres-hive-metastore pg_isready -U postgres
```

### Subir archivos a HDFS

```powershell
# Copiar archivo local al contenedor
docker cp "archivo.csv" hadoop-master:/tmp/archivo.csv

# Subir archivo a HDFS desde el contenedor
docker exec hadoop-master hdfs dfs -put /tmp/archivo.csv /user/hive/data/

# Ver archivos en HDFS
docker exec hadoop-master hdfs dfs -ls /user/hive/data/
```

**Nota**: TambiÃ©n puedes subir archivos directamente desde la interfaz web de HDFS en http://localhost:9870/explorer.html

## ğŸ› SoluciÃ³n de Problemas

### Hive no puede conectarse al Metastore

```powershell
# Verificar que PostgreSQL estÃ© corriendo
docker-compose ps postgres

# Ver logs del Metastore
docker-compose logs hive-metastore

# Verificar conectividad
docker exec hive-metastore nc -zv postgres 5432
```

### Error en inicializaciÃ³n de esquema de Hive

```powershell
# Reinicializar el esquema manualmente
docker exec -it hive-metastore bash
schematool -dbType postgres -initSchema

# O eliminar el volumen de PostgreSQL y recrear
docker-compose down -v
docker-compose up -d
```

### HiveServer2 no responde

```powershell
# Ver logs de HiveServer2
docker-compose logs -f hive-server

# Verificar que el Metastore estÃ© disponible
docker exec hive-server nc -zv hive-metastore 9083

# Reiniciar HiveServer2
docker-compose restart hive-server
```

## ğŸ“š DocumentaciÃ³n Adicional

- **[Hive - GuÃ­a completa de uso](docs/HIVE_Documentacion.md)** - Consultas SQL, ejemplos y comandos
- **[HDFS - Permisos y configuraciÃ³n](docs/HDFS_Permisos_Documentacion.md)** - GestiÃ³n de permisos en HDFS

## ğŸ› ï¸ Estructura del Proyecto

```
HadoopSparkLocal/
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ hadoop/                     # ConfiguraciÃ³n de Hadoop
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ start-hadoop.sh
â”‚   â””â”€â”€ config/                 # Archivos de configuraciÃ³n HDFS/YARN
â”œâ”€â”€ spark/                      # ConfiguraciÃ³n de Spark
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ start-spark.sh
â”œâ”€â”€ hive/                       # ConfiguraciÃ³n de Hive
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ start-hive.sh
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ hive-site.xml
â”œâ”€â”€ postgres/                   # InicializaciÃ³n de PostgreSQL
â”‚   â””â”€â”€ init-hive-metastore.sh
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â””â”€â”€ docs/                       # DocumentaciÃ³n
    â”œâ”€â”€ HIVE_Documentacion.md
    â””â”€â”€ HDFS_Permisos_Documentacion.md
```

## ğŸ¯ Casos de Uso

### 1. AnÃ¡lisis de datos con SQL (Hive)
- Crear tablas sobre datos en HDFS
- Ejecutar consultas SQL complejas
- Particionamiento y optimizaciÃ³n

### 2. Machine Learning con Spark
- Usar PySpark en Jupyter
- Procesamiento distribuido
- IntegraciÃ³n con bibliotecas de ML

### 3. ETL (Extract, Transform, Load)
- Cargar datos desde mÃºltiples fuentes
- Transformar con Hive o Spark
- Almacenar en HDFS con formato optimizado

### 4. Data Warehouse
- Usar Hive como capa SQL sobre HDFS
- Metastore compartido entre Hive y Spark
- Consultas desde herramientas BI via JDBC

## âš ï¸ ResoluciÃ³n de Problemas Comunes

### Hive: ClassCastException con Java
**SÃ­ntoma:** HiveServer2 no inicia, error `ClassCastException` en los logs.  
**Causa:** Hive 3.1.3 no es compatible con Java 11+.  
**SoluciÃ³n:** Verificar que el Dockerfile de Hive use `openjdk-8-jdk`.

### Hive: User root is not allowed to impersonate
**SÃ­ntoma:** Error al ejecutar consultas desde Hive.  
**Causa:** Hadoop no tiene configurado proxy user para Hive.  
**SoluciÃ³n:** Verificar que `hadoop/config/core-site.xml` tenga las propiedades `hadoop.proxyuser.root.*` y reiniciar Hadoop.

### HiveServer2 tarda mucho en iniciar
**SÃ­ntoma:** El servicio no responde inmediatamente.  
**Causa:** Normal. HiveServer2 requiere 2-3 minutos para inicializar.  
**SoluciÃ³n:** Esperar. El health check tiene un `start_period` de 120 segundos.

### PostgreSQL: Connection refused
**SÃ­ntoma:** Hive Metastore no puede conectar a PostgreSQL.  
**Causa:** PostgreSQL aÃºn no estÃ¡ listo.  
**SoluciÃ³n:** Verificar `docker-compose logs postgres-hive-metastore` y esperar.

Para mÃ¡s detalles, consultar:
- `docs/HIVE_Documentacion.md` - Troubleshooting completo
- `docs/HIVE_Implementacion_Final.md` - Resumen de problemas resueltos

---

**ğŸ’¡ Tips:**
- PostgreSQL usa el puerto **5433** (en lugar del estÃ¡ndar 5432) para evitar conflictos con otras instalaciones locales.
- Hive requiere **Java 8**. No usar Java 11+ debido a incompatibilidades.
- HiveServer2 puede tardar varios minutos en inicializar la primera vez.


